{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import wrappers\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ACTIONS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CartPole with Agent manually trained by player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# env = gym.make('CartPoleU-v0')\n",
    "gym.envs.register(\n",
    "    id='CartPoleUV-v0',\n",
    "    entry_point='gym.envs.classic_control:CartPoleEnv',\n",
    "    max_episode_steps=5000,      # MountainCar-v0 uses 200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-22 16:16:52,874] Making new env: CartPoleUV-v0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPoleUV-v0')\n",
    "env.mode = 'human'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_action_from_tanh(value):\n",
    "    return 1 if value[0][0]>value[0][1] else 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reverse_action(action):\n",
    "    return 1 if action == 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IS_HUMAN_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist_observations = []\n",
    "hist_actions = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-22 16:26:30,439] Making new env: CartPoleUV-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTIONS=2\n",
      "Press keys 1 2 3 ... to take actions 1 2 3 ...\n",
      "No keys pressed is taking action 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-9c6a1de367fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0mrollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-9c6a1de367fa>\u001b[0m in \u001b[0;36mrollout\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "from __future__ import print_function\n",
    "import time\n",
    "import random\n",
    "import sys, gym\n",
    "\n",
    "\n",
    "# Test yourself as a learning agent! Pass environment name as a command-line argument.\n",
    "#\n",
    "window_size = 2\n",
    "\n",
    "action_obser_hist = []\n",
    "\n",
    "hist_observations_epoch = []\n",
    "hist_actions_epoch = []\n",
    "\n",
    "env = gym.make('CartPoleUV-v0')\n",
    "\n",
    "if not hasattr(env.action_space, 'n'):\n",
    "    raise Exception('Keyboard agent only supports discrete action spaces')\n",
    "ACTIONS = env.action_space.n\n",
    "ROLLOUT_TIME = 1000\n",
    "SKIP_CONTROL = 0    # Use previous control decision SKIP_CONTROL times, that's how you\n",
    "                    # can test what skip is still usable.\n",
    "\n",
    "human_agent_action = 0\n",
    "human_wants_restart = False\n",
    "human_sets_pause = False\n",
    "waiting_for_human_action = True\n",
    "\n",
    "def key_press(key, mod):\n",
    "    global human_agent_action, human_wants_restart, human_sets_pause, waiting_for_human_action\n",
    "    \n",
    "    if key==0xff0d: human_wants_restart = True\n",
    "    if key==32: human_sets_pause = not human_sets_pause\n",
    "        \n",
    "    a = int( key - ord('0') )\n",
    "    \n",
    "    if a < 0 or a >= ACTIONS: return\n",
    "    \n",
    "    human_agent_action = a\n",
    "    waiting_for_human_action = False\n",
    "\n",
    "def key_release(key, mod):\n",
    "    global human_agent_action, waiting_for_human_action\n",
    "    a = int( key - ord('0') )\n",
    "    if a < 0 or a >= ACTIONS: return\n",
    "#     if human_agent_action == a:\n",
    "#         human_agent_action = 0\n",
    "#     waiting_for_human_action = True\n",
    "\n",
    "env.render()\n",
    "env.unwrapped.viewer.window.on_key_press = key_press\n",
    "env.unwrapped.viewer.window.on_key_release = key_release\n",
    "\n",
    "def rollout(env):\n",
    "    global human_agent_action, human_wants_restart, human_sets_pause, waiting_for_human_action, hist_actions, hist_observations, hist_observations_epoch, hist_actions_epoch, action_obser_hist, window_size\n",
    "    \n",
    "    human_wants_restart = False\n",
    "    obser = env.reset()\n",
    "    skip = 0\n",
    "    for t in range(ROLLOUT_TIME):\n",
    "        # Human teaching the NN        \n",
    "        if IS_HUMAN_MODE:\n",
    "            if not skip:\n",
    "                #print(\"taking action {}\".format(human_agent_action))\n",
    "                a = human_agent_action\n",
    "                skip = SKIP_CONTROL\n",
    "            else:\n",
    "                skip -= 1\n",
    "            \n",
    "            hist_actions_epoch.append(a)\n",
    "            hist_observations_epoch.append(obser)\n",
    "            a = reverse_action(a)\n",
    "        \n",
    "        # NN balansing POLE by herself\n",
    "        else:\n",
    "            action_obser_hist.append(np.array(obser).reshape([1, 4]))\n",
    "            a = model.predict(np.array(action_obser_hist).reshape([1, -1, 4]))\n",
    "            a = get_action_from_tanh(a)\n",
    "            a = reverse_action(a)\n",
    "            \n",
    "            if len(action_obser_hist) == window_size:    \n",
    "                del action_obser_hist[0]\n",
    "#                 print('Predicted action: ', a)\n",
    "                \n",
    "#             else: \n",
    "#                 a = random.choice([1,0])\n",
    "            \n",
    "        obser, r, done, info = env.step(a)\n",
    "\n",
    "        \n",
    "        if IS_HUMAN_MODE and done:\n",
    "            hist_actions.append(hist_actions_epoch[:-10])\n",
    "            hist_observations.append(hist_observations_epoch[:-10])\n",
    "            hist_actions_epoch = []\n",
    "            hist_observations_epoch = []\n",
    "        \n",
    "        elif not IS_HUMAN_MODE and done:\n",
    "            action_obser_hist = []\n",
    "            \n",
    "        env.render()\n",
    "        time.sleep(0.1)\n",
    "\n",
    "        if done: break\n",
    "        if human_wants_restart: break\n",
    "        \n",
    "        while waiting_for_human_action and IS_HUMAN_MODE:\n",
    "            env.render()\n",
    "            time.sleep(0.5)\n",
    "\n",
    "print(\"ACTIONS={}\".format(ACTIONS))\n",
    "print(\"Press keys 1 2 3 ... to take actions 1 2 3 ...\")\n",
    "print(\"No keys pressed is taking action 0\")\n",
    "\n",
    "while 1:\n",
    "    rollout(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, SimpleRNN, Dropout\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(4, input_shape=[4], activation='relu', kernel_initializer='random_uniform'))\n",
    "    model.add(Dense(6, activation='relu', kernel_initializer='random_uniform'))\n",
    "    model.add(Dense(2, activation='tanh', kernel_initializer='random_uniform'))\n",
    "    return model\n",
    "\n",
    "def get_reccurent_model():\n",
    "    model = Sequential()\n",
    "#     model.add(LSTM(16, input_shape=(4, 1), return_sequences=False))\n",
    "#     model.add(LSTM(16, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(2, activation='tanh', kernel_initializer='random_uniform'))\n",
    "    return model\n",
    "\n",
    "def get_reccurent_stateful_model():\n",
    "    model = Sequential()\n",
    "#     model.add(SimpleRNN(1, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "    # Maybe more neurons needed     \n",
    "    # Not stateful\n",
    "    model.add(LSTM(4, input_dim=4, return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(4))\n",
    "    model.add(Dropout(0.1))\n",
    "    # Stateful\n",
    "#     model.add(LSTM(16, batch_input_shape=(1, 4, 1), stateful=True, return_sequences=True))\n",
    "#     model.add(LSTM(16, stateful=True))\n",
    "#     model.add(SimpleRNN(4, batch_input_shape=(1, 4, 1), stateful=True, ))\n",
    "#     model.add(LSTM(16, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(2, activation='tanh', kernel_initializer='random_uniform'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create chunks from mini parts\n",
    "window_size = 2\n",
    "\n",
    "X_chunked = []\n",
    "Y_chunked = []\n",
    "\n",
    "for i, obs in enumerate(hist_observations):\n",
    "    obs = np.array(obs)\n",
    "\n",
    "    for j in range(obs.shape[0] - window_size):\n",
    "        X_chunked.append(obs[j:j+window_size])\n",
    "        Y_chunked.append(hist_actions[i][j+window_size-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((0,), (0,))\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X_chunked)\n",
    "Y = np.array(Y_chunked)\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = np.concatenate([Y.reshape(-1, 1),np.zeros(Y.shape).reshape(-1, 1)], axis=1)\n",
    "Y[:, 1][Y[:,0] == 0] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:26: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:26: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(4, return_sequences=True, input_shape=(None, 4))`\n"
     ]
    }
   ],
   "source": [
    "model = get_reccurent_stateful_model()\n",
    "model.compile(Adam(), 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.load('./data/AgentLearning/train_data.npz')\n",
    "X = test['x']\n",
    "Y = test['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(767, 2, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3714 - acc: 0.8377     \n",
      "Epoch 2/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3589 - acc: 0.8435     \n",
      "Epoch 3/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3894 - acc: 0.8279     \n",
      "Epoch 4/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3925 - acc: 0.8318     \n",
      "Epoch 5/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3808 - acc: 0.8240     \n",
      "Epoch 6/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3736 - acc: 0.8435     \n",
      "Epoch 7/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3875 - acc: 0.8246     \n",
      "Epoch 8/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3755 - acc: 0.8175     \n",
      "Epoch 9/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3800 - acc: 0.8338     \n",
      "Epoch 10/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3972 - acc: 0.8325     \n",
      "Epoch 11/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3833 - acc: 0.8246     \n",
      "Epoch 12/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3914 - acc: 0.8305     \n",
      "Epoch 13/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3745 - acc: 0.8344     \n",
      "Epoch 14/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3926 - acc: 0.8318     \n",
      "Epoch 15/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3757 - acc: 0.8383     \n",
      "Epoch 16/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3686 - acc: 0.8357     \n",
      "Epoch 17/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3875 - acc: 0.8305     \n",
      "Epoch 18/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3760 - acc: 0.8383     \n",
      "Epoch 19/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3660 - acc: 0.8207     \n",
      "Epoch 20/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3659 - acc: 0.8214     \n",
      "Epoch 21/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3589 - acc: 0.8429     \n",
      "Epoch 22/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3778 - acc: 0.8351     \n",
      "Epoch 23/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3632 - acc: 0.8377     \n",
      "Epoch 24/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3886 - acc: 0.8344     \n",
      "Epoch 25/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3697 - acc: 0.8305     \n",
      "Epoch 26/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3842 - acc: 0.8312     \n",
      "Epoch 27/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3817 - acc: 0.8357     \n",
      "Epoch 28/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3820 - acc: 0.8331     \n",
      "Epoch 29/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3840 - acc: 0.8286     \n",
      "Epoch 30/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3626 - acc: 0.8318     \n",
      "Epoch 31/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3732 - acc: 0.8266     \n",
      "Epoch 32/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3603 - acc: 0.8416     \n",
      "Epoch 33/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3852 - acc: 0.8305     \n",
      "Epoch 34/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3804 - acc: 0.8338     \n",
      "Epoch 35/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3590 - acc: 0.8455     \n",
      "Epoch 36/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3913 - acc: 0.8286     \n",
      "Epoch 37/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3996 - acc: 0.8207     \n",
      "Epoch 38/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3587 - acc: 0.8475     \n",
      "Epoch 39/10000\n",
      "767/767 [==============================] - 0s - loss: 0.4009 - acc: 0.8325     \n",
      "Epoch 40/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3562 - acc: 0.8481     \n",
      "Epoch 41/10000\n",
      "767/767 [==============================] - 0s - loss: 0.4158 - acc: 0.8312     \n",
      "Epoch 42/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3780 - acc: 0.8435     \n",
      "Epoch 43/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3981 - acc: 0.8305     \n",
      "Epoch 44/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3758 - acc: 0.8390     \n",
      "Epoch 45/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3471 - acc: 0.8396     \n",
      "Epoch 46/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3905 - acc: 0.8462     \n",
      "Epoch 47/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3848 - acc: 0.8409     \n",
      "Epoch 48/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3768 - acc: 0.8501     \n",
      "Epoch 49/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3683 - acc: 0.8455     \n",
      "Epoch 50/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3967 - acc: 0.8351     \n",
      "Epoch 51/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3693 - acc: 0.8351     \n",
      "Epoch 52/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3366 - acc: 0.8462     \n",
      "Epoch 53/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3610 - acc: 0.8481     \n",
      "Epoch 54/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3920 - acc: 0.8338     \n",
      "Epoch 55/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3673 - acc: 0.8462     \n",
      "Epoch 56/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3466 - acc: 0.8533     \n",
      "Epoch 57/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3760 - acc: 0.8416     \n",
      "Epoch 58/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3643 - acc: 0.8449     \n",
      "Epoch 59/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3697 - acc: 0.8449     \n",
      "Epoch 60/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3730 - acc: 0.8416     \n",
      "Epoch 61/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3560 - acc: 0.8325     \n",
      "Epoch 62/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3680 - acc: 0.8396     \n",
      "Epoch 63/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3689 - acc: 0.8403     \n",
      "Epoch 64/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3860 - acc: 0.8462     \n",
      "Epoch 65/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3644 - acc: 0.8351     \n",
      "Epoch 66/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3638 - acc: 0.8422     \n",
      "Epoch 67/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3698 - acc: 0.8409     - ETA: 0s - loss: 0.3331 - acc: 0.\n",
      "Epoch 68/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3480 - acc: 0.8422     \n",
      "Epoch 69/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3809 - acc: 0.8409     \n",
      "Epoch 70/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3547 - acc: 0.8507     \n",
      "Epoch 71/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3631 - acc: 0.8449     \n",
      "Epoch 72/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3599 - acc: 0.8455     \n",
      "Epoch 73/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3637 - acc: 0.8475     \n",
      "Epoch 74/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3361 - acc: 0.8527     \n",
      "Epoch 75/10000\n",
      "767/767 [==============================] - 0s - loss: 0.4066 - acc: 0.8488     \n",
      "Epoch 76/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3352 - acc: 0.8553     \n",
      "Epoch 77/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3587 - acc: 0.8514     \n",
      "Epoch 78/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3280 - acc: 0.8605     \n",
      "Epoch 79/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3737 - acc: 0.8409     \n",
      "Epoch 80/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3494 - acc: 0.8481     \n",
      "Epoch 81/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3508 - acc: 0.8579     \n",
      "Epoch 82/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3667 - acc: 0.8475     \n",
      "Epoch 83/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3365 - acc: 0.8383     \n",
      "Epoch 84/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3689 - acc: 0.8390     \n",
      "Epoch 85/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3744 - acc: 0.8435     \n",
      "Epoch 86/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "767/767 [==============================] - 0s - loss: 0.3622 - acc: 0.8572     \n",
      "Epoch 87/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3727 - acc: 0.8553     \n",
      "Epoch 88/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3704 - acc: 0.8585     \n",
      "Epoch 89/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3573 - acc: 0.8605     \n",
      "Epoch 90/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3242 - acc: 0.8501     \n",
      "Epoch 91/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3421 - acc: 0.8501     \n",
      "Epoch 92/10000\n",
      "767/767 [==============================] - ETA: 0s - loss: 0.3539 - acc: 0.850 - 0s - loss: 0.3576 - acc: 0.8422     \n",
      "Epoch 93/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3616 - acc: 0.8377     \n",
      "Epoch 94/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3524 - acc: 0.8468     \n",
      "Epoch 95/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3430 - acc: 0.8488     \n",
      "Epoch 96/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3263 - acc: 0.8514     \n",
      "Epoch 97/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3722 - acc: 0.8507     \n",
      "Epoch 98/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3785 - acc: 0.8468     \n",
      "Epoch 99/10000\n",
      "767/767 [==============================] - 0s - loss: 0.4912 - acc: 0.8162     \n",
      "Epoch 100/10000\n",
      "767/767 [==============================] - 0s - loss: 0.4953 - acc: 0.8142     \n",
      "Epoch 101/10000\n",
      "767/767 [==============================] - 0s - loss: 0.4383 - acc: 0.8181     \n",
      "Epoch 102/10000\n",
      "767/767 [==============================] - 0s - loss: 0.4109 - acc: 0.8220     \n",
      "Epoch 103/10000\n",
      "767/767 [==============================] - 0s - loss: 0.4474 - acc: 0.8240     \n",
      "Epoch 104/10000\n",
      "767/767 [==============================] - 0s - loss: 0.4203 - acc: 0.8240     \n",
      "Epoch 105/10000\n",
      "767/767 [==============================] - 0s - loss: 0.4019 - acc: 0.8168     \n",
      "Epoch 106/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3940 - acc: 0.8220     \n",
      "Epoch 107/10000\n",
      "767/767 [==============================] - 0s - loss: 0.4044 - acc: 0.8253     \n",
      "Epoch 108/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3877 - acc: 0.8370     \n",
      "Epoch 109/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3544 - acc: 0.8312     \n",
      "Epoch 110/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3730 - acc: 0.8207     \n",
      "Epoch 111/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3753 - acc: 0.8246     \n",
      "Epoch 112/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3944 - acc: 0.8279     \n",
      "Epoch 113/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3514 - acc: 0.8409     \n",
      "Epoch 114/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3543 - acc: 0.8377     \n",
      "Epoch 115/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3845 - acc: 0.8253     \n",
      "Epoch 116/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3645 - acc: 0.8318     \n",
      "Epoch 117/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3742 - acc: 0.8286     \n",
      "Epoch 118/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3541 - acc: 0.8422     \n",
      "Epoch 119/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3702 - acc: 0.8435     \n",
      "Epoch 120/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3504 - acc: 0.8338     \n",
      "Epoch 121/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3735 - acc: 0.8299     \n",
      "Epoch 122/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3394 - acc: 0.8403     \n",
      "Epoch 123/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3593 - acc: 0.8429     \n",
      "Epoch 124/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3558 - acc: 0.8357     \n",
      "Epoch 125/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3581 - acc: 0.8357     \n",
      "Epoch 126/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3497 - acc: 0.8396     \n",
      "Epoch 127/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3455 - acc: 0.8579     \n",
      "Epoch 128/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3580 - acc: 0.8429     \n",
      "Epoch 129/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3622 - acc: 0.8409     \n",
      "Epoch 130/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3678 - acc: 0.8409     \n",
      "Epoch 131/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3528 - acc: 0.8527     \n",
      "Epoch 132/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3399 - acc: 0.8422     \n",
      "Epoch 133/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3590 - acc: 0.8462     \n",
      "Epoch 134/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3423 - acc: 0.8468     \n",
      "Epoch 135/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3744 - acc: 0.8357     \n",
      "Epoch 136/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3626 - acc: 0.8409     \n",
      "Epoch 137/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3551 - acc: 0.8462     \n",
      "Epoch 138/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3666 - acc: 0.8390     \n",
      "Epoch 139/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3586 - acc: 0.8475     \n",
      "Epoch 140/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3417 - acc: 0.8442     \n",
      "Epoch 141/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3413 - acc: 0.8462     \n",
      "Epoch 142/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3474 - acc: 0.8416     \n",
      "Epoch 143/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3419 - acc: 0.8520     \n",
      "Epoch 144/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3522 - acc: 0.8429     \n",
      "Epoch 145/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3500 - acc: 0.8429     \n",
      "Epoch 146/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3412 - acc: 0.8501     \n",
      "Epoch 147/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3582 - acc: 0.8481     \n",
      "Epoch 148/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3750 - acc: 0.8468     \n",
      "Epoch 149/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3343 - acc: 0.8507     \n",
      "Epoch 150/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3615 - acc: 0.8435     \n",
      "Epoch 151/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3422 - acc: 0.8533     \n",
      "Epoch 152/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3438 - acc: 0.8455     \n",
      "Epoch 153/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3523 - acc: 0.8435     \n",
      "Epoch 154/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3492 - acc: 0.8409     \n",
      "Epoch 155/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3441 - acc: 0.8507     \n",
      "Epoch 156/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3329 - acc: 0.8553     \n",
      "Epoch 157/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3516 - acc: 0.8494     \n",
      "Epoch 158/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3368 - acc: 0.8553     \n",
      "Epoch 159/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3438 - acc: 0.8481     \n",
      "Epoch 160/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3473 - acc: 0.8416     \n",
      "Epoch 161/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3437 - acc: 0.8396     \n",
      "Epoch 162/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3666 - acc: 0.8377     \n",
      "Epoch 163/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3417 - acc: 0.8468     \n",
      "Epoch 164/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3463 - acc: 0.8462     \n",
      "Epoch 165/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3259 - acc: 0.8514     \n",
      "Epoch 166/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3597 - acc: 0.8566     \n",
      "Epoch 167/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3570 - acc: 0.8449     \n",
      "Epoch 168/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3447 - acc: 0.8429     \n",
      "Epoch 169/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3600 - acc: 0.8481     \n",
      "Epoch 170/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3532 - acc: 0.8514     \n",
      "Epoch 171/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "767/767 [==============================] - 0s - loss: 0.3464 - acc: 0.8527     \n",
      "Epoch 172/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3405 - acc: 0.8488     \n",
      "Epoch 173/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3684 - acc: 0.8488     \n",
      "Epoch 174/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3337 - acc: 0.8579     \n",
      "Epoch 175/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3310 - acc: 0.8462     \n",
      "Epoch 176/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3468 - acc: 0.8481     \n",
      "Epoch 177/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3480 - acc: 0.8527     \n",
      "Epoch 178/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3263 - acc: 0.8488     \n",
      "Epoch 179/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3347 - acc: 0.8585     \n",
      "Epoch 180/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3650 - acc: 0.8455     \n",
      "Epoch 181/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3494 - acc: 0.8520     \n",
      "Epoch 182/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3460 - acc: 0.8468     \n",
      "Epoch 183/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3433 - acc: 0.8488     \n",
      "Epoch 184/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3371 - acc: 0.8553     \n",
      "Epoch 185/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3538 - acc: 0.8455     \n",
      "Epoch 186/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3393 - acc: 0.8462     \n",
      "Epoch 187/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3483 - acc: 0.8559     \n",
      "Epoch 188/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3505 - acc: 0.8488     \n",
      "Epoch 189/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3765 - acc: 0.8481     \n",
      "Epoch 190/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3792 - acc: 0.8546     \n",
      "Epoch 191/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3446 - acc: 0.8533     \n",
      "Epoch 192/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3388 - acc: 0.8625     \n",
      "Epoch 193/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3468 - acc: 0.8533     \n",
      "Epoch 194/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3255 - acc: 0.8566     \n",
      "Epoch 195/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3848 - acc: 0.8383     \n",
      "Epoch 196/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3732 - acc: 0.8481     \n",
      "Epoch 197/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3480 - acc: 0.8527     \n",
      "Epoch 198/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3511 - acc: 0.8435     \n",
      "Epoch 199/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3406 - acc: 0.8540     \n",
      "Epoch 200/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3663 - acc: 0.8514     \n",
      "Epoch 201/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3404 - acc: 0.8409     \n",
      "Epoch 202/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3383 - acc: 0.8507     \n",
      "Epoch 203/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3469 - acc: 0.8475     \n",
      "Epoch 204/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3432 - acc: 0.8481     \n",
      "Epoch 205/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3287 - acc: 0.8546     \n",
      "Epoch 206/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3647 - acc: 0.8468     \n",
      "Epoch 207/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3938 - acc: 0.8435     \n",
      "Epoch 208/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3467 - acc: 0.8533     \n",
      "Epoch 209/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3566 - acc: 0.8540     \n",
      "Epoch 210/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3593 - acc: 0.8592     \n",
      "Epoch 211/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3550 - acc: 0.8520     \n",
      "Epoch 212/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3949 - acc: 0.8501     \n",
      "Epoch 213/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3378 - acc: 0.8611     \n",
      "Epoch 214/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3692 - acc: 0.8403     \n",
      "Epoch 215/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3604 - acc: 0.8514     \n",
      "Epoch 216/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3273 - acc: 0.8514     \n",
      "Epoch 217/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3779 - acc: 0.8383     \n",
      "Epoch 218/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3243 - acc: 0.8449     \n",
      "Epoch 219/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3171 - acc: 0.8611     \n",
      "Epoch 220/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3842 - acc: 0.8481     \n",
      "Epoch 221/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3357 - acc: 0.8540     \n",
      "Epoch 222/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3435 - acc: 0.8494     \n",
      "Epoch 223/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3989 - acc: 0.8579     \n",
      "Epoch 224/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3694 - acc: 0.8468     \n",
      "Epoch 225/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3566 - acc: 0.8520     \n",
      "Epoch 226/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3480 - acc: 0.8533     \n",
      "Epoch 227/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3410 - acc: 0.8416     \n",
      "Epoch 228/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3493 - acc: 0.8520     \n",
      "Epoch 229/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3202 - acc: 0.8598     \n",
      "Epoch 230/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3329 - acc: 0.8475     \n",
      "Epoch 231/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3560 - acc: 0.8664     \n",
      "Epoch 232/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3239 - acc: 0.8481     \n",
      "Epoch 233/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3544 - acc: 0.8572     \n",
      "Epoch 234/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3361 - acc: 0.8625     \n",
      "Epoch 235/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3384 - acc: 0.8527     \n",
      "Epoch 236/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3543 - acc: 0.8527     \n",
      "Epoch 237/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3352 - acc: 0.8611     \n",
      "Epoch 238/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3232 - acc: 0.8631     \n",
      "Epoch 239/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3333 - acc: 0.8540     \n",
      "Epoch 240/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3390 - acc: 0.8527     \n",
      "Epoch 241/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3475 - acc: 0.8520     \n",
      "Epoch 242/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3566 - acc: 0.8435     \n",
      "Epoch 243/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3421 - acc: 0.8546     \n",
      "Epoch 244/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3299 - acc: 0.8546     \n",
      "Epoch 245/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3468 - acc: 0.8468     \n",
      "Epoch 246/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3621 - acc: 0.8520     \n",
      "Epoch 247/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3214 - acc: 0.8585     \n",
      "Epoch 248/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3387 - acc: 0.8631     \n",
      "Epoch 249/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3060 - acc: 0.8638     \n",
      "Epoch 250/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3580 - acc: 0.8585     \n",
      "Epoch 251/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3151 - acc: 0.8585     \n",
      "Epoch 252/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3552 - acc: 0.8481     \n",
      "Epoch 253/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3238 - acc: 0.8488     \n",
      "Epoch 254/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3377 - acc: 0.8611     \n",
      "Epoch 255/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3171 - acc: 0.8579     \n",
      "Epoch 256/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "767/767 [==============================] - 0s - loss: 0.3116 - acc: 0.8533     \n",
      "Epoch 257/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3468 - acc: 0.8481     \n",
      "Epoch 258/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3649 - acc: 0.8592     \n",
      "Epoch 259/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3302 - acc: 0.8657     \n",
      "Epoch 260/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3216 - acc: 0.8546     \n",
      "Epoch 261/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3665 - acc: 0.8462     \n",
      "Epoch 262/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3089 - acc: 0.8559     \n",
      "Epoch 263/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3336 - acc: 0.8638     \n",
      "Epoch 264/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3422 - acc: 0.8572     \n",
      "Epoch 265/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3358 - acc: 0.8501     \n",
      "Epoch 266/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3440 - acc: 0.8559     \n",
      "Epoch 267/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3475 - acc: 0.8514     \n",
      "Epoch 268/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3491 - acc: 0.8598     \n",
      "Epoch 269/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3320 - acc: 0.8579     \n",
      "Epoch 270/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3322 - acc: 0.8546     \n",
      "Epoch 271/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3374 - acc: 0.8592     \n",
      "Epoch 272/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3656 - acc: 0.8416     \n",
      "Epoch 273/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3122 - acc: 0.8664     \n",
      "Epoch 274/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3520 - acc: 0.8566     \n",
      "Epoch 275/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3149 - acc: 0.8625     \n",
      "Epoch 276/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3607 - acc: 0.8527     \n",
      "Epoch 277/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3888 - acc: 0.8546     \n",
      "Epoch 278/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3390 - acc: 0.8553     \n",
      "Epoch 279/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3267 - acc: 0.8611     \n",
      "Epoch 280/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3320 - acc: 0.8618     \n",
      "Epoch 281/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3389 - acc: 0.8585     \n",
      "Epoch 282/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3358 - acc: 0.8559     \n",
      "Epoch 283/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3253 - acc: 0.8605     \n",
      "Epoch 284/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3223 - acc: 0.8475     \n",
      "Epoch 285/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3336 - acc: 0.8683     \n",
      "Epoch 286/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3263 - acc: 0.8501     \n",
      "Epoch 287/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3096 - acc: 0.8677     \n",
      "Epoch 288/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3310 - acc: 0.8618     \n",
      "Epoch 289/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3290 - acc: 0.8677     \n",
      "Epoch 290/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3141 - acc: 0.8572     \n",
      "Epoch 291/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3251 - acc: 0.8664     \n",
      "Epoch 292/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3182 - acc: 0.8598     \n",
      "Epoch 293/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3121 - acc: 0.8546     \n",
      "Epoch 294/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3102 - acc: 0.8605     \n",
      "Epoch 295/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3466 - acc: 0.8716     \n",
      "Epoch 296/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3600 - acc: 0.8403     \n",
      "Epoch 297/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3100 - acc: 0.8585     \n",
      "Epoch 298/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3233 - acc: 0.8572     \n",
      "Epoch 299/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3612 - acc: 0.8507     \n",
      "Epoch 300/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3504 - acc: 0.8598     \n",
      "Epoch 301/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3340 - acc: 0.8501     \n",
      "Epoch 302/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3332 - acc: 0.8533     \n",
      "Epoch 303/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3291 - acc: 0.8540     \n",
      "Epoch 304/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3271 - acc: 0.8572     \n",
      "Epoch 305/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3358 - acc: 0.8598     \n",
      "Epoch 306/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3288 - acc: 0.8455     \n",
      "Epoch 307/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3225 - acc: 0.8572     \n",
      "Epoch 308/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3338 - acc: 0.8572     \n",
      "Epoch 309/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3083 - acc: 0.8683     \n",
      "Epoch 310/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3130 - acc: 0.8683     \n",
      "Epoch 311/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3045 - acc: 0.8585     \n",
      "Epoch 312/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3048 - acc: 0.8651     \n",
      "Epoch 313/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3532 - acc: 0.8533     \n",
      "Epoch 314/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3307 - acc: 0.8475     \n",
      "Epoch 315/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3117 - acc: 0.8455     \n",
      "Epoch 316/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3357 - acc: 0.8611     \n",
      "Epoch 317/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3238 - acc: 0.8494     \n",
      "Epoch 318/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3558 - acc: 0.8657     \n",
      "Epoch 319/10000\n",
      "767/767 [==============================] - 0s - loss: 0.3390 - acc: 0.8507     \n",
      "Epoch 320/10000\n",
      "608/767 [======================>.......] - ETA: 0s - loss: 0.3425 - acc: 0.8544"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2cde2d9a55d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Stateless training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Stateless training\n",
    "model.fit(X, Y, verbose=1, epochs=10000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ! not tested method\n",
    "# Statefull training\n",
    "for i in range(100000):\n",
    "    if not i % 10:\n",
    "        flag_verb = 1\n",
    "        print('Epoch: ', i)\n",
    "    else:\n",
    "        flag_verb = 1\n",
    "        \n",
    "    model.fit(X_train.reshape((-1, 4, 1)), y_train, epochs=1, validation_data=[X_test.reshape((-1, 4, 1)), y_test], batch_size=1, verbose=flag_verb, shuffle=False)\n",
    "    model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez_compressed('./data/AgentLearning/train_data', x=X, y=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
